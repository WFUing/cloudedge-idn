
\chapter{绪论}

\section{研究背景}

近年来，物联网（Internet of Things, IoT）和人工智能（Artificial Intelligence, AI）技术的快速发展推动了网络边缘设备数量的显著增长，随之而来的是数据规模的持续扩大和计算需求的显著增加 \cite{chataut2023unleashing}。特别是在智能工业 \cite{elahi2023comprehensive, xu2022review, mohamed2019leveraging}、城市交通 \cite{almukhalfi2024traffic, sayed2023artificial} 和智慧家居 \cite{krejcar2020technology, 黄倩怡2020智能家居中的边缘计算, guo2019review} 等领域，深度学习凭借其卓越的特征提取能力和高效的决策支持能力，逐渐成为推动智能化发展的核心驱动力。然而，这些场景对实时性、服务质量（Quality of Service, QoS）的要求日益严格，使得传统云计算模式的缺陷逐渐显现\cite{andriulo2024edge}，集中式云计算模式将海量数据从终端设备传输至远端数据中心处理。尽管其强大的服务器算力能为资源受限的设备提供支持，但端到端延迟受限于计算延迟与通信延迟的双重制约\cite{wang2024end}。其中，计算延迟取决于模型复杂度和硬件性能，而通信延迟则受广域网带宽及网络拥塞的影响。在数据密集型应用中，频繁的数据传输加剧了网络负担，导致延迟增加和响应时间的不确定性，难以满足实时性需求\cite{xu2021modelling}。

为应对这些局限性，边缘计算（Edge Computing）作为一种新兴计算范式应运而生。通过将计算任务下沉至靠近数据源的边缘节点，边缘计算大幅缩短了数据传输距离，减少了带宽占用，降低了通信延迟，从而提升了实时响应能力\cite{chowdhury2019co,施巍松2019边缘计算}。与此同时，出现了多种轻量化模型构建技术，包括通过模型剪枝（Model Pruning）去除冗余参数\cite{han2015deep}、利用量化（Quantization）降低运算精度\cite{jacob2018quantization}以及采用知识蒸馏（Knowledge Distillation）迁移大型模型知识至小型模型\cite{hinton2015distilling}等方法，从而为边缘设备部署深度学习模型提供了可行性。然而，边缘节点受限于计算能力、存储容量和能耗预算等硬件约束，其动态资源调度能力与弹性扩展能力仍存在显著不足。因此，如何协调边缘端有限的资源与云端的强大算力，以实现高效的任务分配与资源管理，成为亟待解决的关键问题。

云边协同通过整合云端的全局调度与边缘的本地执行，提供了一种有效的解决路径，能够降低延迟并提升资源利用率。然而，当前云边平台在深度学习的实际应用中仍面临诸多挑战。首先，调度机制需要具备对网络状态和设备负载的实时感知能力，以在动态环境下实现高效资源分配。其次，边缘设备硬件架构的高度异构性导致系统在模型集成与部署过程中缺乏灵活性，难以快速适配新型设备或支持多样化的深度学习模型。此外，云端与边缘端之间的资源分布不均衡进一步加剧了调度的复杂性，亟需设计合理的调度策略，以在节点间进行优化选择并实现高效的协同工作。基于此，本文尝试研究云边协同环境下的模型推理调度技术，以解决这些问题。具体而言，本文将围绕以下关键挑战展开探索：

\begin{enumerate}
    \item[1.] 如何构建动态环境感知机制，实现网络状态与设备负载的实时监测，从而支持基于QoS约束的自适应资源分配决策？
    \item[2.] 如何设计通用且灵活的模型集成与部署机制，以应对边缘设备硬件异构性带来的挑战，使系统能够高效支持多类型深度学习模型并快速适配新型设备？
    \item[3.] 如何在云端与边缘端资源分布不均衡的情况下，设计相关调度策略，优化节点间的选择与协作，以平衡负载并提升整体系统性能？
\end{enumerate}

本文旨在构建一个灵活的云边协同调度系统，主要研究高效调度算法的设计，并深入探讨动态环境感知机制和异构设备适配与模型部署技术。通过实时监测网络状态和设备负载，提升调度精度；实现高效的调度算法与模型适配机制，从而提高资源利用率和任务执行效率，减少端到端延迟并增强服务质量。该系统将为智能工业、城市交通及智能家居等领域提供可靠的技术支持，促进其在需要实时决策和高可靠性场景中的广泛应用。

\section{研究现状}

云计算自诞生以来，凭借虚拟化技术和大规模数据中心架构，为各行业提供了弹性且可扩展的资源共享模式。随后，容器化技术和微服务架构的引入催生了云原生概念，进一步提升了云端系统的可移植性与交付效率\cite{deng2024cloud}。在此过程中，Kubernetes\cite{kubernetes} 和 Docker Swarm\cite{dockerswarm} 等编排工具成为云原生生态的核心支柱，实现了大规模集群管理和自动化部署。基于这些先进的云端技术，工业界逐渐将云计算的计算、网络与存储能力延伸至边缘侧，以满足低延迟和高可靠性的应用需求。目前，较为成熟的边缘计算方案包括 Rancher 公司开发的 K3s\cite{fogli2021performance}、华为贡献给云原生基金会（CNCF）的 KubeEdge\cite{xiong2018extend} 以及阿里巴巴开源的 OpenYurt\cite{openyurt2023}。这些方案依托 Kubernetes 的容器编排与管理能力，通过功能裁剪适应边缘场景的资源约束。其中，KubeEdge 和 OpenYurt 进一步扩展了边缘自治能力，能够在网络不稳定或与云端短暂失联时维持关键服务的运行，而 K3s 则更侧重于轻量化部署，缺乏专门的云边协同组件。尽管这些工具在一定程度上支持云边协同，但其负载均衡机制仍沿用传统云端任务分配逻辑，在动态环境下的适应性和资源调度效率方面存在不足，难以完全满足云边协同场景对低延迟和高可靠性的要求。

在学术界，部分研究人员基于上述工业界提供的平台展开资源调度问题的探索。例如，Shan等人\cite{shan2024kces}在KubeEdge的基础上提出了KCES工作流容器化调度方案，通过云边工作流调度引擎以及任务水平漫游与垂直卸载策略，有效优化了资源利用率并降低了任务延迟。然而，该方案的调度设计更倾向于处理具有固定依赖关系的任务序列，未能充分适应真实云边场景中由设备数据驱动的动态调度需求。Mutichiro等人\cite{mutichiro2021qos}针对边缘服务器在同时接收大量任务时可能因过载而导致任务队列延长和网络拥塞的问题，提出了一种基于蚁群优化的服务时间感知调度算法（STaSA），以优化资源利用率、服务时间和调度成本，从而确保整体性能达到最优。然而，该研究主要聚焦于边缘节点之间的协同调度，未充分考虑云边一体化环境下的全局优化潜力。在计算卸载领域，学者们进一步探索了动态环境下的任务分配机制。例如，Urgaonkar等\cite{urgaonkar2015dynamic}将调度建模为马尔可夫决策过程，结合李雅普诺夫优化实现实时资源调整；Han等\cite{han2019ondisc}提出的OnDisc算法通过残余密度优先策略满足延迟敏感任务需求；Meng等\cite{meng2019online}设计的Dedas算法引入截止期限约束，优化多节点卸载效率；部分研究\cite{崔玉亚2021一种面向移动边缘计算的多用户细粒度任务卸载调度方法,邝祝芳2022基于深度强化学习的多用户边缘计算任务卸载调度与资源分配算法,郑守建2022一种基于综合匹配度的边缘计算系统任务调度方法,张斐斐2023边缘计算中协作计算卸载与动态任务调度}利用启发式或强化学习方法提升调度性能。然而，这些研究大多针对通用计算负载，尚未充分考虑云边环境下模型推理的服务质量需求，同时缺乏对动态环境感知和模型集成与部署的有效支持，这限制了其在实际应用中的适用性。

AI 模型通常涉及两种典型的部署方式，一种是边缘节点以低吞吐量为代价提供强实时性的推理服务，另一种是云端依托机器学习即服务（MLaaS）支持高吞吐量的复杂模型推理\cite{salem2023toward}。将模型推理能力集成到终端设备与云端之间的连续体中，需要复杂的资源编排机制。现有研究提出了多种云边协同下的计算卸载方案，但这些方案在云边协同模型推理的实际应用中仍存在诸多不足，主要包括以下几个方面：

\begin{itemize} 
    \item \textbf{节点状态监测欠缺}：现有的云边平台在节点资源监控方面主要依赖 Kubernetes 提供的基础指标（如内存、磁盘使用率等），但对其他关键资源（如网络带宽、传输时延等）的实时监控支持不足。这种局限性导致系统难以实现负载的最优调度，并可能因调度决策滞后而影响整体系统的响应速度和运行效率。
    \item \textbf{负载均衡能力局限}：边缘节点的计算资源和负载分布往往存在显著差异，而当前云边平台的负载均衡机制难以根据节点的实时负载动态调整任务分配，导致无法实现精细化的负载管理。同时，如何高效协调边缘节点与云端之间、以及边缘节点之间的资源分配与任务调度，仍然是一个亟待解决的关键问题。
    \item \textbf{QoS 评估体系不健全}：当前一些调度策略在设计和实现过程中仅关注有限的服务质量需求，缺乏全面的评估体系。在实际云边协同场景中，深度学习应用的服务质量（QoS）指标呈现多维度和复杂性的特点，不仅包括延迟，还涉及节点之间的带宽消耗、任务可靠性、资源利用率等关键因素。此外，不同层次的云边架构对服务质量的要求可能存在差异，这进一步增加了构建统一 QoS 模型的难度，限制了系统在复杂场景中的适应性。
    \item \textbf{模型部署兼容性不足}：边缘节点的异构性导致 AI 模型部署面临兼容性问题。一方面，不同边缘节点的硬件架构差异显著，影响模型的兼容性和性能。另一方面，不同深度学习框架训练的模型无法直接在其他框架的环境中运行。这种兼容性问题不仅增加了模型部署的复杂性，还可能导致性能下降和资源浪费。
\end{itemize}

针对上述局限性，迫切需要研究面向模型推理的云边协同调度技术，并设计高度适配的优化方案。该方案应紧密结合云边协同环境的特点，实现节点状态的精细化管理，全面感知网络带宽、传输时延等关键指标。在负载均衡策略上进行深度优化，充分考虑边缘节点与云端之间的资源分布差异及动态变化特性，并兼顾深度学习应用的服务质量指标，从而提升系统的整体调度效率和适应能力。在模型部署方面，要充分考虑云边环境下计算节点的异构性，简化部署流程。

\section{本文工作}

为解决上述研究问题并弥补现有工作的不足，本文提出了一种面向云边协同的模型推理调度技术框架。首先，本文在“云-边-端”架构的三层物理拓扑基础上抽象出树状逻辑拓扑，并详细分析了从设备产生流式数据到模型推理实例执行的全过程，以及每个节点在收到模型推理任务请求时的行为。在此基础上，本文设计了一个形式化的面向模型推理的云边协同调度模型。该模型形式化地定义了云边环境下模型推理的核心要素，包括计算节点、终端设备和模型推理实例，并明确了流式数据调度的核心开销。进一步，本文设计并实现了一种结合贪心策略与多维度优先级队列的调度算法。该算法针对云层和边层的节点提出了最大数据量优先和最小任务优先的优化策略。这些策略充分考虑了各层资源的异构性、设备调度的成功率以及网络带宽的限制，从而实现了从局部到全局的多层次优化。

在上述调度框架基础上，本文设计并实现了一个原型系统 KEAS（Kubernetes-Enhanced Adaptive Scheduling system），以验证该框架的可行性和有效性。该系统利用 KubeEdge 的设备管理工具实现了从边缘节点高效采集传感器或设备生成的流式数据，通过 Akka 集群技术，实现了分布式调度和数据转发。为适配边缘环境的异构化特点，本文设计了模型推理服务模块。该模块不仅支持多种硬件架构的边缘节点，还兼容主流的深度学习框架。为优化推理性能，本文在模型推理之前引入了批处理机制，通过对批量数据的预处理和分析，有效监测节点的计算性能和负载情况。与此同时，利用网络探针实时监测网络状况，包括带宽利用率、延迟和丢包率等关键指标，从而为调度器提供全面的调度依据。上述模块的设计为调度器的高效运行提供了坚实的数据支撑。

本文的主要贡献总结如下：

\begin{enumerate}
    \item[1.] \textbf{面向模型推理的云边协同调度模型。} 针对现有云边协同方案在模型推理场景下缺乏统一优化框架的问题，本文构建了一个形式化的面向模型推理的云边协同调度模型。该模型通过定义终端设备、模型推理实例、计算节点等核心组件及其交互机制，明确了云边协同环境下的资源分配与任务调度的基本要素和核心开销。在此基础上，模型引入了数据流驱动的动态调度框架，设计了分层委托策略及相应的调度算法，以优化云边协同推理过程。
    \item[2.] \textbf{KEAS原型系统。} 本文设计并实现了一个基于KubeEdge的面向模型推理的云边协同调度模型系统 KEAS，解决了现有云边平台在动态环境感知、负载均衡和 QoS 保障方面的不足。KEAS 的核心在于实现了分层委托策略及相应的调度算法。为支持这一复杂的调度机制，系统利用 Akka 集群集成了模型批处理测试、实时监控探针和数据路由等功能组件，有效支撑设备数据流请求的高效调度，实现了云边协同环境下的模型推理优化。
    \item[3.] \textbf{全面实验评估。} 本文通过全面的实验评估，结果表明 KEAS 系统在边缘设备调度成功率和设备请求调度成功率方面显著优于现有的负载均衡算法。此外，KEAS 展现出良好的异构计算节点适配能力，并支持不同深度学习框架之间的模型转换，从而大幅增强了系统的灵活性与兼容性。同时，通过引入推理批处理机制，系统吞吐量得到了进一步提升。
\end{enumerate}

\section{本文组织结构}

本文按照以下结构组织各章节内容：

第二章为背景知识，介绍研究的背景与基础知识，涵盖云边协同计算架构、云原生技术、Kubernetes 技术栈、AI 推理部署方法以及 Actor 编程模式。这些内容为后续章节中提出的调度方法和系统设计奠定了理论基础和技术支撑。

第三章详细探讨了面向模型推理的云边协同调度。首先，本章介绍了云边协同的拓扑结构、模型推理任务的特点及分层推理流程，阐明了该环境的复杂性和挑战。基于此，提出了一种形式化的云边协同模型推理调度模型，该模型定义了终端设备、计算节点以及模型推理实例。这些定义为后续的调度算法提供了坚实的理论基础。在此基础上，设计并实现了一种结合贪心策略与多维度优先级队列的调度算法，以优化云边协同推理过程。

第四章探讨了基于前述方法的KEAS原型系统的设计与实现。本章首先介绍了KubeEdge及其相关技术，包括其架构设计、设备管理机制和服务通信机制，并描述了系统与KubeEdge的依赖关系。接着，详细介绍了系统的整体架构及各组件的功能定位与协作关系。此外，重点分析了关键组件的设计与实现，包括基于 Akka 的调度服务、系统协调服务、模型推理服务、数据路由服务和系统监控服务。通过这些组件，系统能够支持前文提出的调度算法，确保在云边协同环境中高效完成模型推理任务的调度与执行。

第五章对 KEAS 系统进行全面实验评估，分为核心算法仿真、系统功能验证和性能评估三部分。核心算法仿真实验通过模拟云边环境中的计算节点与设备流式数据生成过程，验证分层调度优化算法在服务质量指标上的表现。系统功能验证实验测试各核心模块的功能完整性，确保其稳定运行与协同能力。系统性能评估实验深入分析了分层调度决策对响应时间的影响。

第六章总结本文的研究工作，归纳提出方法与系统的创新点及实验成果，同时分析当前研究的局限性并展望未来方向，包括优化云边协同机制和支持更多类型的模型推理任务。
