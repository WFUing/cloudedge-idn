
\chapter{绪论}

\section{研究背景}

近年来，随着物联网（Internet of Things, IoT）和人工智能（Artificial Intelligence, AI）等技术的迅猛发展，网络边缘设备的数量急剧增加，数据规模持续扩大，进而带来了巨大的计算需求\cite{verma2017survey}。在这些需求中，深度学习在智能工业\cite{yan2017industrial,zhang2017self,peres2018idarts,mohamed2019leveraging}、城市交通\cite{jia2017edge,mohamed2017smartcityware,mallapuram2017smart,dalla2017using}、智慧家居\cite{savio2018smart,krejcar2020technology,黄倩怡2020智能家居中的边缘计算}等领域中发挥着至关重要的作用。云计算可将云端服务器的强大算力赋能给性能有限的终端设备，使其同样能够获取高效的计算与存储服务\cite{shafi20175g}。然而在传统的云计算范式下，数据需要传输到中心数据中心进行处理，这在带宽需求高的场景中会造成显著的网络负载，逐渐难以满足这些应用场景对服务质量（Quality of Service, QoS）的要求\cite{wang2024end}：

\begin{itemize} 
\item \textbf{响应时间}：深度学习应用的响应时间由计算延迟和通信延迟共同决定，其中计算延迟与模型规模和可用算力等因素相关；而通信延迟则受当前通信技术所限。由于广域网最初旨在提高带宽容量与链路效率，在大规模数据传输时不可避免地会出现高延迟、网络拥塞和不稳定等问题。
\item \textbf{数据安全和隐私}：传统云计算往往将数据传输到云端进行存储与分析，但加解密的高成本在一定程度上阻碍了其广泛应用。此外，随着数据隐私和安全意识提升，去中心化并在可行的情况下强调在数据源处或附近进行处理变得至关重要。
\end{itemize}

为应对上述挑战，将深度学习模型部署到更贴近数据源的边缘节点成为一种可行的解决方案，即边缘计算。与传统云计算不同，边缘计算则将计算任务下放至网络边缘，减少了数据的回传时间和带宽消耗，从而缩短数据传输距离和响应时间，显著提高了应用的实时响应能力，同时增强数据隐私\cite{chowdhury2019co,khan2019edge,liu2019survey,施巍松2019边缘计算,刘通2021边缘计算中任务卸载研究综述}。然而，边缘端的性能受到硬件资源和能耗等方面的限制。虽然可以采用一些轻量级模型以降低计算和存储需求，但这往往会牺牲一定的\textbf{模型准确率}，使其难以满足某些对系统可靠性要求较高的应用场景。在这种情况下，需将计算请求转发至云端或其他具备足够资源的边缘端进行处理。由此可见，云端和边缘端的协同工作，即云边协同，是应对各个场景需求的关键。

综上所述，在云边协同计算模式下，合理分配计算资源以平衡模型的准确性、响应延时和资源利用率，并将深度学习模型部署到适当的节点以满足特定应用需求，仍然是一个具有挑战性的问题。本文聚焦于云边协同环境下的深度学习推理服务供应系统，旨在通过节点间的协作，优化服务质量指标的平衡，进而满足推理服务的多样化需求。具体的研究内容包括以下几个方面：

\begin{enumerate}
\item[1.] 如何在云端与边缘端之间选择最合适的部署位置，以满足服务质量指标的深度学习模型需求，实现不同层次之间的垂直协作，从而优化资源分配并提升整体系统性能。
\item[2.] 如何在同一层级的多个计算节点之间实现高效协作，例如边缘计算节点之间的协作，实现水平协作，进而提高系统的可扩展性、稳健性和负载均衡能力。
\end{enumerate}

我们认为，实现云边协同环境下的深度学习推理服务供应系统具有重要意义，不仅可以显著提高系统的资源利用率和任务执行效率，提升系统整体性能，还能满足用户对服务低延迟和高可靠性的需求，推动其在更广泛的领域和场景中的应用。

\section{研究现状}

云计算自诞生以来，通过虚拟化技术和大规模数据中心架构，为各行业提供了弹性且可扩展的资源共享模式。随后，容器化技术及微服务架构的引入，推动了云原生概念的兴起，进一步提升了云端系统的可移植性与交付效率\cite{deng2024cloud}。在此过程中，Kubernetes\cite{kubernetes}、Docker Swarm\cite{dockerswarm}等编排工具成为云原生生态的重要支柱，使大规模集群管理与自动化部署成为现实。基于这些先进的云端技术与架构，工业界开始将云的计算、网络与存储能力延伸至边缘侧，以满足低延时和高可靠性的应用需求，其中较为成熟的方案包括 Rancher 公司开发维护的 k3s\cite{fogli2021performance}、华为贡献给云原生基金会（CNCF）的 KubeEdge\cite{xiong2018extend} 以及阿里巴巴开源的 OpenYurt\cite{openyurt2023}。它们均依托于 Kubernetes 的容器编排与管理能力，在此基础上进行功能裁剪或扩展，满足边缘场景下的资源约束与分布式需求，同时提供了一定的边缘自治能力，使系统在网络不稳定或与云端短暂失联时仍能维持关键服务。但是，这些方案在云边协同下的高效调度方面仍有不足：k3s 缺少专门的云边协同组件；KubeEdge 和 OpenYurt 虽然引入了更精细的节点分组与管理，但仍基于传统云端分配任务的调度算法，难以完全满足云边协同场景下对低延迟和高可靠性的需求，在部署位置的选择上仍存在优化空间。综合评估后，本系统研究最终选用 KubeEdge 作为底层架构，主要基于以下考虑：

\begin{itemize} 
\item \textbf{云边协同的原生支持}：KubeEdge 从框架设计上就将“云-边-端”融为一体，提供丰富的边缘设备管理和数据处理能力。与缺乏云边协同组件的 k3s 相比，KubeEdge 更适合大规模、多功能的边缘计算场景；与 OpenYurt 相比，KubeEdge 对边缘端资源的要求更低，并在边缘设备管理上表现更佳。
\item \textbf{良好的社区生态与文档}：KubeEdge 作为 CNCF 项目，拥有高活跃度的社区和成熟的文档、示例及教程。与其他方案相比，它能够在开发与运维阶段提供更完善的支持。 
\end{itemize}

在学术界，研究人员也针对云边协同下的计算卸载问题提出了多种方案。Urgaonkar等人\cite{urgaonkar2015dynamic}将负载调度问题建模为马尔可夫决策过程，并结合李雅普诺夫优化，使调度算法能够根据当前系统负载进行实时调整，从而在不确定条件下保持系统的稳定性与高效性。Han 等人\cite{han2019ondisc}等人提出了一种名为 OnDisc 的在线负载调度与卸载算法，在单个节点上定义了残余密度（Residual Density）的度量，通过“最高残余密度优先”来满足对延迟敏感的负载需求；在多节点场景中，OnDisc 通过最小化计算卸载所带来的总加权响应时间来进一步降低整体延迟。Meng等人\cite{meng2019online}则提出名为 Dedas 的在线负载调度和卸载算法，量化网络带宽对传输时延的影响，并引入了“截至期限”（Deadline）的概念，在单节点内使用最早截止期限优先调度策略，在多节点间则通过最小化负载完成时间来实现高效的卸载与调度。此外，部分研究\cite{崔玉亚2021一种面向移动边缘计算的多用户细粒度任务卸载调度方法,邝祝芳2022基于深度强化学习的多用户边缘计算任务卸载调度与资源分配算法,郑守建2022一种基于综合匹配度的边缘计算系统任务调度方法,张斐斐2023边缘计算中协作计算卸载与动态任务调度}还借助启发式策略或强化学习方法设计调度算法，以进一步提升调度效率和系统性能。

然而，以上工作均针对通用计算负载，仅考虑时延对服务质量的影响，未能充分考虑深度学习应用中准确率对系统性能的影响。这一局限性限制了现有调度算法在需要高精度计算的深度学习场景中的应用效果，无法全面优化系统的资源分配和整体性能。针对这一问题，Salem 等人\cite{salem2023toward}提出了推理交付网络（Inference Delivery Network，IDN）的概念，旨在解决机器学习模型在设备端与云端部署时面临的延迟与准确性之间的权衡。同时，他们提出了一种名为 INFIDA 的模型分配分布式动态策略，采用在线镜像上升（Online Mirror Ascent，OMA）的方法加速收敛，并有效应对非凸决策空间和复杂成本函数。然而，Salem 等人的研究未能充分考虑如何根据实时变化的应用场景动态调整深度学习模型在云端和边缘节点之间的部署位置，导致其在适应动态服务质量需求方面表现不佳。例如，当某些节点出现异常或即将发生故障时，为了及时采取措施避免生产中断，模型推理的延迟要求可能会急剧提高，而准确性要求则可能在一定程度上有所降低。

现有研究提出了多种云边协同下的计算卸载方案，但这些方案目前仍处于理论分析阶段，尚未在实际工业开发环境中得到应用。将这些调度策略从理论模型转化为实际部署需要克服多方面的挑战，主要包括以下几个方面：

\begin{itemize} 
\item \textbf{节点状态监测欠缺}：现有的云边协同方案在节点资源监控方面主要依赖 Kubernetes 的 内存、磁盘等监测，缺乏对其他关键资源（如网络带宽、传输时延等）的实时监控。这导致无法实现负载的最优调度，并可能因调度决策滞后而影响整体系统的响应速度。
\item \textbf{服务质量指标单一}：在实际云边协同场景中，深度学习应用场景的服务质量指标是多维度的，不只有延迟，还涉及模型准确率、可靠性、资源利用率等关键因素。
\item \textbf{动态 QoS 需求不适应}：实际应用中的服务质量需求往往是动态变化的，可能遇到的网络波动、节点掉线等情况。因此，模型分配策略需要能够根据实时变化的应用场景，动态调整深度学习模型在云端和边缘节点之间的部署位置，以最优地满足多维度的服务质量需求。
\item \textbf{负载均衡能力局限}：边缘节点的计算资源和负载情况可能存在较大差异。当前的负载均衡机制难以根据节点的实时负载情况，动态调整任务分配，从而难以实现精细化的负载均衡，影响系统的整体性能和可靠性。
\end{itemize}

针对以上局限性，本文开展了工作：


\section{研究问题和本文工作}

\section{本文组织结构}
