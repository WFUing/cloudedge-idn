\chapter{总结与展望}

\section{工作总结}

近年来，物联网与人工智能的快速发展推动了边缘设备数量和计算需求的激增。在智能工业、城市交通和智慧家居等领域，深度学习已成为智能化发展的核心驱动力。然而，这些场景对实时性和服务质量（QoS）的要求日益严格，传统云计算模式因通信延迟和带宽限制难以满足需求。边缘计算通过将任务下沉至靠近数据源的边缘节点，大幅减少了通信开销并提升了实时性。尽管轻量化模型技术为边缘设备部署提供了可能，但边缘资源有限且调度弹性不足的问题依然突出。因此，如何通过云边协同优化任务分配与资源管理，成为具有重要研究价值的关键问题。

云边协同整合了云端全局调度与边缘本地执行的优势，为降低延迟和提升资源利用率提供了有效路径。然而，当前云边协同平台仍面临诸多挑战：首先，动态环境下的高效调度需实时感知网络状态与设备负载，并基于QoS约束进行自适应分配；其次，边缘设备硬件异构性导致系统在模型集成与部署中缺乏灵活性，难以支持多样化模型或快速适配新型设备；最后，云端与边缘端资源分布不均衡进一步加剧了调度复杂性，亟需设计合理的策略以优化节点间协作。

针对上述问题，本文提出了一种云边协同AI推理调度方案KEAS，主要贡献和结果总结如下：

\begin{itemize} 
    \item 提出了一个面向模型推理的云边协同调度模型，将云边环境抽象为树状拓扑结构，形式化定义了终端设备、模型推理实例和计算节点等核心组件及其交互机制，设计了覆盖边缘到云端的分层调度委托策略及相应的调度算法，以优化云边协同推理过程。
    \item 实现了一个基于KubeEdge的面向模型推理的云边协同调度系统，集成了分层调度器、调度决策及实时监控探针等功能组件，解决了现有平台在动态环境感知、负载均衡和QoS保障、模型推理实例部署方面的不足。
    \item 开展了全面的实验评估，验证了 KEAS 系统在边缘设备调度成功率和设备请求调度成功率方面的优越性，超越现有负载均衡算法。
\end{itemize}

\section{研究展望}

本文未来的工作主要有以下几个方向：

\begin{enumerate}
    \item[1.] \textbf{支持对边缘异构网络的适配}。 当前系统对网络环境的处理采用黑盒方式，仅通过测试网络性能进行调度决策，而未深入分析网络的具体特性。然而，边缘网络具有多样性，包括不同的协议、拓扑结构和传输介质，这些因素可能显著影响调度效果。未来的研究将致力于实际分析网络特性，设计更加精细的网络适配机制。
    \item[2.] \textbf{实现GPU资源的划分与多类型AI加速器支持}。目前Kubernetes（K8S）对GPU资源的管理方式较为简单，通常直接绑定整个GPU设备，缺乏细粒度的资源分割能力。此外，对其他AI加速器（如VPU、TPU等）的支持也较为有限。未来的工作将在系统中引入模块化设计，实现对GPU资源的虚拟化和量化分割，同时扩展对多种AI加速器的支持。这不仅能提高硬件资源利用率，还能为不同类型的AI推理任务提供更灵活的资源分配方案。
    \item[3.] \textbf{结合模型分割技术优化云边协同调度} 当前的AI推理任务通常以完整模型的形式部署在单一节点上，这种方式难以充分利用云边协同架构的优势，尤其是在资源受限的边缘环境中可能存在性能瓶颈。未来的研究将探索模型分割技术，将大型AI模型分解为多个子模块，并根据各模块的计算复杂度和通信需求，将其动态分配到云端或边缘的不同节点上执行。结合分层调度委托策略，可以进一步细化任务分配策略，在保障服务质量的同时实现负载均衡和资源高效利用。例如，对于计算密集型模块可优先分配至云端，而对于时延敏感型模块则可在边缘节点本地执行。
\end{enumerate}
